{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djg/snap/jupyter/common/lib/python3.7/site-packages/joblib/_multiprocessing_helpers.py:45: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    \n",
    "import matplotlib.patches as mpatches \n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SqueezeNet(nb_classes, inputs=(3, 224, 224)):\n",
    "    \"\"\" Keras Implementation of SqueezeNet(arXiv 1602.07360)\n",
    "    Arguments:\n",
    "        nb_classes: total number of final categories\n",
    "        \n",
    "        inputs -- shape of the input images (channel, cols, rows)\n",
    "    \"\"\"\n",
    "\n",
    "    input_img = Input(shape=inputs)\n",
    "    conv1 = Convolution2D(\n",
    "        96, 7, 7, activation='relu', init='glorot_uniform',\n",
    "        subsample=(2, 2), border_mode='same', name='conv1')(input_img)\n",
    "    maxpool1 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool1')(conv1)\n",
    "\n",
    "    fire2_squeeze = Convolution2D(\n",
    "        16, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire2_squeeze')(maxpool1)\n",
    "    fire2_expand1 = Convolution2D(\n",
    "        64, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire2_expand1')(fire2_squeeze)\n",
    "    fire2_expand2 = Convolution2D(\n",
    "        64, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire2_expand2')(fire2_squeeze)\n",
    "    merge2 = merge(\n",
    "        [fire2_expand1, fire2_expand2], mode='concat', concat_axis=1)\n",
    "\n",
    "    fire3_squeeze = Convolution2D(\n",
    "        16, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire3_squeeze')(merge2)\n",
    "    fire3_expand1 = Convolution2D(\n",
    "        64, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire3_expand1')(fire3_squeeze)\n",
    "    fire3_expand2 = Convolution2D(\n",
    "        64, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire3_expand2')(fire3_squeeze)\n",
    "    merge3 = merge(\n",
    "        [fire3_expand1, fire3_expand2], mode='concat', concat_axis=1)\n",
    "\n",
    "    fire4_squeeze = Convolution2D(\n",
    "        32, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire4_squeeze')(merge3)\n",
    "    fire4_expand1 = Convolution2D(\n",
    "        128, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire4_expand1')(fire4_squeeze)\n",
    "    fire4_expand2 = Convolution2D(\n",
    "        128, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire4_expand2')(fire4_squeeze)\n",
    "    merge4 = merge(\n",
    "        [fire4_expand1, fire4_expand2], mode='concat', concat_axis=1)\n",
    "    maxpool4 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool4')(merge4)\n",
    "\n",
    "    fire5_squeeze = Convolution2D(\n",
    "        32, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire5_squeeze')(maxpool4l)\n",
    "    fire5_expand1 = Convolution2D(\n",
    "        128, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire5_expand1')(fire5_squeeze)\n",
    "    fire5_expand2 = Convolution2D(\n",
    "        128, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire5_expand2')(fire5_squeeze)\n",
    "    merge5 = merge(\n",
    "        [fire5_expand1, fire5_expand2], mode='concat', concat_axis=1)\n",
    "\n",
    "    fire6_squeeze = Convolution2D(\n",
    "        48, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire6_squeeze')(merge5)\n",
    "    fire6_expand1 = Convolution2D(\n",
    "        192, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire6_expand1')(fire6_squeeze)\n",
    "    fire6_expand2 = Convolution2D(\n",
    "        192, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire6_expand2')(fire6_squeeze)\n",
    "    merge6 = merge(\n",
    "        [fire6_expand1, fire6_expand2], mode='concat', concat_axis=1)\n",
    "\n",
    "    fire7_squeeze = Convolution2D(\n",
    "        48, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire7_squeeze')(merge6)\n",
    "    fire7_expand1 = Convolution2D(\n",
    "        192, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire7_expand1')(fire7_squeeze)\n",
    "    fire7_expand2 = Convolution2D(\n",
    "        192, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire7_expand2')(fire7_squeeze)\n",
    "    merge7 = merge(\n",
    "        [fire7_expand1, fire7_expand2], mode='concat', concat_axis=1)\n",
    "\n",
    "    fire8_squeeze = Convolution2D(\n",
    "        64, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire8_squeeze')(merge7)\n",
    "    fire8_expand1 = Convolution2D(\n",
    "        256, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire8_expand1')(fire8_squeeze)\n",
    "    fire8_expand2 = Convolution2D(\n",
    "        256, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire8_expand2')(fire8_squeeze)\n",
    "    merge8 = merge(\n",
    "        [fire8_expand1, fire8_expand2], mode='concat', concat_axis=1)\n",
    "\n",
    "    maxpool8 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool8')(merge8)\n",
    "\n",
    "    fire9_squeeze = Convolution2D(\n",
    "        64, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire9_squeeze')(maxpool8)\n",
    "    fire9_expand1 = Convolution2D(\n",
    "        256, 1, 1, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire9_expand1')(fire9_squeeze)\n",
    "    fire9_expand2 = Convolution2D(\n",
    "        256, 3, 3, activation='relu', init='glorot_uniform',\n",
    "        border_mode='same', name='fire9_expand2')(fire9_squeeze)\n",
    "    merge9 = merge(\n",
    "        [fire9_expand1, fire9_expand2], mode='concat', concat_axis=1)\n",
    "\n",
    "    fire9_dropout = Dropout(0.5, name='fire9_dropout')(merge9)\n",
    "    conv10 = Convolution2D(\n",
    "        nb_classes, 1, 1, init='glorot_uniform',\n",
    "        border_mode='valid', name='conv10')(fire9_dropout)\n",
    "    # The size should match the output of conv10\n",
    "    avgpool10 = AveragePooling2D((13, 13), name='avgpool10')(conv10)\n",
    "\n",
    "    flatten = Flatten(name='flatten')(avgpool10)\n",
    "    softmax = Activation(\"softmax\", name='softmax')(flatten)\n",
    "\n",
    "    return Model(input=input_img, output=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AccLossPlotter(Callback):\n",
    "    \"\"\"Plot training Accuracy and Loss values on a Matplotlib graph. \n",
    "    The graph is updated by the 'on_epoch_end' event of the Keras Callback class\n",
    "    # Arguments\n",
    "        graphs: list with some or all of ('acc', 'loss')\n",
    "        save_graph: Save graph as an image on Keras Callback 'on_train_end' event \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, graphs=['acc', 'loss'], save_graph=False):\n",
    "        self.graphs = graphs\n",
    "        self.num_subplots = len(graphs)\n",
    "        self.save_graph = save_graph\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.epoch_count = 0\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_count += 1\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        epochs = [x for x in range(self.epoch_count)]\n",
    "\n",
    "        count_subplots = 0\n",
    "        \n",
    "        if 'acc' in self.graphs:\n",
    "            count_subplots += 1\n",
    "            plt.subplot(self.num_subplots, 1, count_subplots)\n",
    "            plt.title('Accuracy')\n",
    "            #plt.axis([0,100,0,1])\n",
    "            plt.plot(epochs, self.val_acc, color='r')\n",
    "            plt.plot(epochs, self.acc, color='b')\n",
    "            plt.ylabel('accuracy')\n",
    "\n",
    "            red_patch = mpatches.Patch(color='red', label='Test')\n",
    "            blue_patch = mpatches.Patch(color='blue', label='Train')\n",
    "\n",
    "            plt.legend(handles=[red_patch, blue_patch], loc=4)\n",
    "\n",
    "        if 'loss' in self.graphs:\n",
    "            count_subplots += 1\n",
    "            plt.subplot(self.num_subplots, 1, count_subplots)\n",
    "            plt.title('Loss')\n",
    "            #plt.axis([0,100,0,5])\n",
    "            plt.plot(epochs, self.val_loss, color='r')\n",
    "            plt.plot(epochs, self.loss, color='b')\n",
    "            plt.ylabel('loss')\n",
    "\n",
    "            red_patch = mpatches.Patch(color='red', label='Test')\n",
    "            blue_patch = mpatches.Patch(color='blue', label='Train')\n",
    "\n",
    "            plt.legend(handles=[red_patch, blue_patch], loc=4)\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        if self.save_graph:\n",
    "            plt.savefig('training_acc_loss.png')\n",
    "\n",
    "class ConfusionMatrix(Callback):\n",
    "    def __init__(self, X_val, Y_val, classes, normalize=False, cmap=plt.cm.Blues, title='Confusion Matrix'):\n",
    "        self.X_val = X_val\n",
    "        self.Y_val = Y_val\n",
    "        self.title = title\n",
    "        self.classes = classes\n",
    "        self.normalize = normalize\n",
    "        self.cmap = cmap\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "\n",
    "#    def on_epoch_end(self, epoch, logs={}):\n",
    "    def on_train_end(self, logs={}):\n",
    "#        print('epoch end')\n",
    "        pred = self.model.predict(self.X_val)\n",
    "        max_pred = np.argmax(pred, axis=1)\n",
    "        max_y = np.argmax(self.Y_val, axis=1)\n",
    "        cnf_mat = confusion_matrix(max_y, max_pred)\n",
    "\n",
    "        plt.imshow(cnf_mat, interpolation='nearest', cmap=self.cmap)\n",
    "        plt.title(self.title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(self.classes))\n",
    "        plt.xticks(tick_marks, self.classes, rotation=45)\n",
    "        plt.yticks(tick_marks, self.classes)\n",
    "\n",
    "        if self.normalize:\n",
    "            cnf_mat = cnf_mat.astype('float') / cnf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        thresh = cnf_mat.max() / 2.\n",
    "        for i, j in itertools.product(range(cnf_mat.shape[0]), range(cnf_mat.shape[1])):\n",
    "            plt.text(j, i, cnf_mat[i, j],                                          \n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cnf_mat[i, j] > thresh else \"black\")\n",
    "                                                                                                         \n",
    "        plt.tight_layout()                                                    \n",
    "        plt.ylabel('True label')                                              \n",
    "        plt.xlabel('Predicted label')                                         \n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "\n",
    "#    def on_train_end(self, logs={}):\n",
    "#        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConfusionMatrixPlotter():\n",
    "\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cmap=plt.cm.Blues, title='Confusion Matrix'):\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "        self.title = title\n",
    "        self.cmap = cmap\n",
    "\n",
    "    def update(self, conf_mat, classes, normalize=False):\n",
    "        \"\"\"This function prints and plots the confusion matrix.\n",
    "        Normalization can be applied by setting `normalize=True`.\n",
    "        \"\"\"\n",
    "        plt.imshow(conf_mat, interpolation='nearest', cmap=self.cmap)\n",
    "        plt.title(self.title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        if normalize:\n",
    "            conf_mat = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        thresh = conf_mat.max() / 2.\n",
    "        for i, j in itertools.product(range(conf_mat.shape[0]), range(conf_mat.shape[1])):\n",
    "            plt.text(j, i, conf_mat[i, j],                                          \n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if conf_mat[i, j] > thresh else \"black\")\n",
    "                                                                                                         \n",
    "        plt.tight_layout()                                                    \n",
    "        plt.ylabel('True label')                                              \n",
    "        plt.xlabel('Predicted label')                                         \n",
    "        plt.draw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(45)\n",
    "nb_class = 2\n",
    "width, height = 224, 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'init')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2a9b10020ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSqueezeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-dc7d80113a21>\u001b[0m in \u001b[0;36mSqueezeNet\u001b[0;34m(nb_classes, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     conv1 = Convolution2D(\n\u001b[1;32m     11\u001b[0m         \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         subsample=(2, 2), border_mode='same', name='conv1')(input_img)\n\u001b[0m\u001b[1;32m     13\u001b[0m     maxpool1 = MaxPooling2D(\n\u001b[1;32m     14\u001b[0m         pool_size=(3, 3), strides=(2, 2), name='maxpool1')(conv1)\n",
      "\u001b[0;32m/home/djg/snap/jupyter/common/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/djg/snap/jupyter/common/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, conv_op, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/djg/snap/jupyter/common/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/djg/snap/jupyter/common/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     }\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/djg/snap/jupyter/common/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    776\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'init')"
     ]
    }
   ],
   "source": [
    "sn = SqueezeNet(nb_classes=nb_class, inputs=(3, height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bcc15de95d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m sn.compile(\n\u001b[0m\u001b[1;32m      6\u001b[0m     optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Build model')\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=0.0002, momentum=0.9, nesterov=True)\n",
    "sn.compile(\n",
    "    optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(sn.summary())\n",
    "\n",
    "# Training\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "nb_epoch = 500\n",
    "\n",
    "#   Generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(width, height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(width, height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Instantiate AccLossPlotter to visualise training\n",
    "plotter = AccLossPlotter(graphs=['acc', 'loss'], save_graph=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "checkpoint = ModelCheckpoint(                                         \n",
    "                'weights.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                monitor='val_loss',                               \n",
    "                verbose=0,                                        \n",
    "                save_best_only=True,                              \n",
    "                save_weights_only=True,                           \n",
    "                mode='min',                                       \n",
    "                period=1)                                         \n",
    "\n",
    "sn.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples, \n",
    "        callbacks=[plotter, checkpoint])\n",
    "\n",
    "sn.save_weights('weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

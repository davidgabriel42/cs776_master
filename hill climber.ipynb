{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f8859be7-fcb2-403a-a961-eddada8d3566",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### run devol with only mutation, no xover\n",
    "\n",
    "removed randomness in num_mutations, set at pop_size\n",
    "\n",
    "!!!need to change selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bc46fb1f-06a7-4639-b0fd-3c735d5232b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import random as rand\n",
    "import csv\n",
    "import operator\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from devol import DEvol, GenomeHandler\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "import inspect\n",
    "from typing import Callable, List\n",
    "import pandas as pd\n",
    "from pyspark.sql import DataFrame, Row, column\n",
    "from pyspark.sql.functions import lit, pandas_udf, PandasUDFType, array\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "75a4096c-033c-470a-bc0c-36f2752cc845",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">GPU accelerated\n",
       "Num GPUs Available:  2\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">GPU accelerated\nNum GPUs Available:  2\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(len(tf.config.experimental.list_physical_devices('GPU')) > 0):\n",
    "  print(\"GPU accelerated\")\n",
    "  print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "  gpu_mode = True\n",
    "else:\n",
    "  print(\"CPU mode\")\n",
    "  gpu_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9644b11b-46aa-434d-80a2-a14addc2a2ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run a genetic algorithm to find an appropriate architecture for some image\n",
    "classification task with Keras+TF.\n",
    "To use, define a `GenomeHandler` defined in genomehandler.py. Then pass it, with\n",
    "training data, to a DEvol instance to run the genetic algorithm. See the readme\n",
    "for more detailed instructions.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import random as rand\n",
    "import csv\n",
    "import operator\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "\n",
    "__all__ = ['DEvol']\n",
    "\n",
    "METRIC_OPS = [operator.__lt__, operator.__gt__]\n",
    "METRIC_OBJECTIVES = [min, max]\n",
    "\n",
    "\n",
    "\n",
    "class DEvol:\n",
    "    \"\"\"\n",
    "    Object which carries out genetic search and returns top performing model\n",
    "    upon completion.\n",
    "    \"\"\"\n",
    "#!!! data_path with checkpointing\n",
    "    def __init__(self, genome_handler, data_path=\"/dbfs/FileStore/runs/_hill_climber\"):\n",
    "        \"\"\"\n",
    "        Initialize a DEvol object which carries out the training and evaluation\n",
    "        of a genetic search.\n",
    "        Args:\n",
    "            genome_handler (GenomeHandler): the genome handler object defining\n",
    "                    the restrictions for the architecture search space\n",
    "            data_path (str): the file which the genome encodings and metric data\n",
    "                    will be stored in\n",
    "        \"\"\"\n",
    "        if(gpu_mode):\n",
    "          self.data_path = data_path + datetime.now().ctime().replace(\":\",\"-\").replace(\" \",\"_\")\n",
    "          data_path = self.data_path\n",
    "          dbutils.fs.mkdirs(data_path )\n",
    "        else:\n",
    "          data_path = \"./\" + datetime.now().ctime().replace(\":\",\"-\").replace(\" \",\"_\")\n",
    "          self.data_path = \"./\" + datetime.now().ctime().replace(\":\",\"-\").replace(\" \",\"_\")\n",
    "        \n",
    "        self.genome_handler = genome_handler\n",
    "        self.datafile = (data_path + 'record.csv')\n",
    "        self._bssf = -1\n",
    "\n",
    "\n",
    "\n",
    "        if os.path.isfile(data_path) and os.stat(data_path).st_size > 1:\n",
    "            raise ValueError(('Non-empty file %s already exists. Please change'\n",
    "                              'file path to prevent overwritten genome data.'\n",
    "                              % data_path))\n",
    "\n",
    "        print(\"Genome encoding and metric data stored at\", self.datafile, \"\\n\")\n",
    "        with open(self.datafile, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',', quotechar='\"',\n",
    "                                quoting=csv.QUOTE_MINIMAL)\n",
    "            metric_cols = [\"Val Loss\", \"Val Accuracy\"]\n",
    "            genome = genome_handler.genome_representation() + metric_cols\n",
    "            writer.writerow(genome)\n",
    "\n",
    "    def set_objective(self, metric):\n",
    "        \"\"\"\n",
    "        Set the metric for optimization. Can also be done by passing to\n",
    "        `run`.\n",
    "        Args:\n",
    "            metric (str): either 'acc' to maximize classification accuracy, or\n",
    "                    else 'loss' to minimize the loss function\n",
    "        \"\"\"\n",
    "        if metric == 'acc':\n",
    "            metric = 'accuracy'\n",
    "        if metric not in ['loss', 'accuracy']:\n",
    "            raise ValueError(('Invalid metric name {} provided - should be'\n",
    "                              '\"accuracy\" or \"loss\"').format(metric))\n",
    "        self._metric = metric\n",
    "        self._objective = \"max\" if self._metric == \"accuracy\" else \"min\"\n",
    "        self._metric_index = 1 if self._metric == 'loss' else -1\n",
    "        self._metric_op = METRIC_OPS[self._objective == 'max']\n",
    "        self._metric_objective = METRIC_OBJECTIVES[self._objective == 'max']\n",
    "       \n",
    "        \n",
    "    def run(self, dataset, num_generations, pop_size, epochs, fitness=None,\n",
    "            metric='accuracy'):\n",
    "        \"\"\"\n",
    "        Run genetic search on dataset given number of generations and\n",
    "        population size\n",
    "        Args:\n",
    "            dataset : tuple or list of numpy arrays in form ((train_data,\n",
    "                    train_labels), (validation_data, validation_labels))\n",
    "            num_generations (int): number of generations to search\n",
    "            pop_size (int): initial population size\n",
    "            epochs (int): epochs for each model eval, passed to keras model.fit\n",
    "            fitness (None, optional): scoring function to be applied to\n",
    "                    population scores, will be called on a numpy array which is\n",
    "                    a min/max scaled version of evaluated model metrics, so It\n",
    "                    should accept a real number including 0. If left as default\n",
    "                    just the min/max scaled values will be used.\n",
    "            metric (str, optional): must be \"accuracy\" or \"loss\" , defines what\n",
    "                    to optimize during search\n",
    "        Returns:\n",
    "            keras model: best model found with weights\n",
    "        \"\"\"\n",
    "        self.set_objective(metric)\n",
    "\n",
    "        # If no validation data is given set it to None\n",
    "        if len(dataset) == 2:\n",
    "            (self.x_train, self.y_train), (self.x_test, self.y_test) = dataset\n",
    "            self.x_val = None\n",
    "            self.y_val = None\n",
    "        else:\n",
    "            (self.x_train, self.y_train), (self.x_test, self.y_test), (self.x_val, self.y_val) = dataset\n",
    "\n",
    "        # generate and evaluate initial population\n",
    "        members = self._generate_random_population(pop_size)\n",
    "        pop = self._evaluate_population(members,\n",
    "                                        epochs,\n",
    "                                        fitness,\n",
    "                                        0,\n",
    "                                        num_generations)\n",
    "\n",
    "        self.pop_size = pop_size\n",
    "        \n",
    "        # evolve\n",
    "        for gen in range(1, num_generations):\n",
    "            members = self._reproduce(pop, gen)\n",
    "            #!!! map to pandas df, apply udf parallel training, save scores\n",
    "            pop = self._evaluate_population(members,\n",
    "                                            epochs,\n",
    "                                            fitness,\n",
    "                                            gen,\n",
    "                                            num_generations)\n",
    "        \n",
    "        #!!!add checkpointing to dbfs\n",
    "\n",
    "        return 1\n",
    "        #return load_model('best-model.h5')\n",
    "\n",
    "    def _reproduce(self, pop, gen):\n",
    "        members = []\n",
    "\n",
    "        # best models survive automatically\n",
    "        members += pop.get_best(len(pop) - int(len(pop) * 0.5))\n",
    "        #double up\n",
    "        members.append(members)\n",
    "        \n",
    "        # randomly mutate\n",
    "        for imem, mem in enumerate(members):\n",
    "            members[imem] = self._mutate(mem, gen)\n",
    "        return members\n",
    "\n",
    "    def _evaluate(self, genome, epochs):\n",
    "        model = self.genome_handler.decode(genome)\n",
    "        loss, accuracy = None, None\n",
    "        fit_params = {\n",
    "            'x': self.x_train,\n",
    "            'y': self.y_train,\n",
    "            'validation_split': 0.1,\n",
    "            'epochs': epochs,\n",
    "            'verbose': 1,\n",
    "            'callbacks': [\n",
    "                EarlyStopping(monitor='val_loss', patience=1, verbose=1)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        if self.x_val is not None:\n",
    "            fit_params['validation_data'] = (self.x_val, self.y_val)\n",
    "        try:\n",
    "            model.fit(**fit_params)\n",
    "            loss, accuracy = model.evaluate(self.x_test, self.y_test, verbose=0)\n",
    "        except Exception as e:\n",
    "            #loss, accuracy = self._handle_broken_model(model, e)\n",
    "            loss = 1\n",
    "            accuracy = 0\n",
    "        try:\n",
    "          self._record_stats(model, genome, loss, accuracy)\n",
    "        except Exception as e:\n",
    "          pass\n",
    "        \n",
    "        return model, loss, accuracy\n",
    "\n",
    "    def _record_stats(self, model, genome, loss, accuracy):\n",
    "        with open(self.datafile, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            row = list(genome) + [loss, accuracy]\n",
    "            writer.writerow(row)\n",
    "\n",
    "        met = loss if self._metric == 'loss' else accuracy\n",
    "        if (self._bssf is -1 or\n",
    "                self._metric_op(met, self._bssf) and\n",
    "                accuracy is not 0):\n",
    "            \n",
    "            self._bssf = met\n",
    "            #azure enforces mlflow saving\n",
    "            mlflow.keras.save_model(model, self.data_path + '/best-model-mlflow')\n",
    "\n",
    "    def _handle_broken_model(self, model, error):\n",
    "        del model\n",
    "\n",
    "        n = self.genome_handler.n_classes\n",
    "        loss = log_loss(np.concatenate(([1], np.zeros(n - 1))), np.ones(n) / n)\n",
    "        accuracy = 1 / n\n",
    "        gc.collect()\n",
    "\n",
    "        if K.backend() == 'tensorflow':\n",
    "            K.clear_session()\n",
    "            tf.reset_default_graph()\n",
    "\n",
    "        print('An error occurred and the model could not train:')\n",
    "        print(error)\n",
    "        print(('Model assigned poor score. Please ensure that your model'\n",
    "               'constraints live within your computational resources.'))\n",
    "        return loss, accuracy\n",
    "\n",
    "    def  p_eval(self, df1, epochs):\n",
    "      #use rdd to parallelize training\n",
    "      \n",
    "      lam = lambda row: transform_row(row)\n",
    "\n",
    "      loss_acc_rdd = df1.rdd.map(lam).collect()\n",
    "      return loss_acc_rdd\n",
    "    \n",
    "    def _evaluate_population(self, members, epochs, fitness, igen, ngen):\n",
    "      fit = []\n",
    "      for imem, mem in enumerate(members):\n",
    "          self._print_evaluation(imem, len(members), igen, ngen)\n",
    "          res = self._evaluate(mem, epochs)\n",
    "          v = res[self._metric_index]\n",
    "          del res\n",
    "          fit.append(v)\n",
    "\n",
    "      fit = np.array(fit)\n",
    "      self._print_result(fit, igen)\n",
    "      return _Population(members, fit, fitness, obj=self._objective)\n",
    "\n",
    "\n",
    "    def _print_evaluation(self, imod, nmod, igen, ngen):\n",
    "        fstr = '\\nmodel {0}/{1} - generation {2}/{3}:\\n'\n",
    "        print(fstr.format(imod + 1, nmod, igen + 1, ngen))\n",
    "\n",
    "    def _generate_random_population(self, size):\n",
    "        return [self.genome_handler.generate() for _ in range(size)]\n",
    "\n",
    "    def _print_result(self, fitness, generation):\n",
    "        result_str = ('Generation {3}:\\t\\tbest {4}: {0:0.4f}\\t\\taverage:'\n",
    "                      '{1:0.4f}\\t\\tstd: {2:0.4f}')\n",
    "        print(result_str.format(self._metric_objective(fitness),\n",
    "                                np.mean(fitness),\n",
    "                                np.std(fitness),\n",
    "                                generation + 1, self._metric))\n",
    "\n",
    "    def _crossover(self, genome1, genome2):\n",
    "        return genome1, genome2\n",
    "\n",
    "    def _uniform_crossover(self,genome1,genome2):\n",
    "        prob_xover = 0.5\n",
    "        for i in range(len(genome1)):\n",
    "          if rand.random() < prob_xover:\n",
    "            genome1[i], genome2[i] = genome2[i], genome1[i]\n",
    "        return genome1, genome2\n",
    "      \n",
    "    def _mutate(self, genome, generation):\n",
    "        # increase mutations as program continues\n",
    "        #num_mutations = max(3, generation // 4)\n",
    "        return self.genome_handler.mutate(genome, self.pop_size)\n",
    "\n",
    "\n",
    "class _Population(object):\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.members)\n",
    "\n",
    "    def __init__(self, members, fitnesses, score, obj='max'):\n",
    "        self.members = members\n",
    "        scores = fitnesses - fitnesses.min()\n",
    "        if scores.max() > 0:\n",
    "            scores /= scores.max()\n",
    "        if obj == 'min':\n",
    "            scores = 1 - scores\n",
    "        if score:\n",
    "            self.scores = score(scores)\n",
    "        else:\n",
    "            self.scores = scores\n",
    "        self.s_fit = sum(self.scores)\n",
    "\n",
    "    def get_best(self, n):\n",
    "        combined = [(self.members[i], self.scores[i])\n",
    "                    for i in range(len(self.members))]\n",
    "        sorted(combined, key=(lambda x: x[1]), reverse=True)\n",
    "        return [x[0] for x in combined[:n]]\n",
    "\n",
    "    \n",
    "      \n",
    "    #fitness proportional selection\n",
    "    def select(self):\n",
    "        dart = rand.uniform(0, self.s_fit)\n",
    "        sum_fits = 0\n",
    "        for i in range(len(self.members)):\n",
    "            sum_fits += self.scores[i]\n",
    "            if sum_fits >= dart:\n",
    "                return self.members[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e6fd6df4-558f-45f4-abc6-e230a4c199cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "class GenomeHandler:\n",
    "    \"\"\"\n",
    "    Defines the configuration and handles the conversion and mutation of\n",
    "    individual genomes. Should be created and passed to a `DEvol` instance.\n",
    "    ---\n",
    "    Genomes are represented as fixed-with lists of integers corresponding\n",
    "    to sequential layers and properties. A model with 2 convolutional layers\n",
    "    and 1 dense layer would look like:\n",
    "    [<conv layer><conv layer><dense layer><optimizer>]\n",
    "    The makeup of the convolutional layers and dense layers is defined in the\n",
    "    GenomeHandler below under self.convolutional_layer_shape and\n",
    "    self.dense_layer_shape. <optimizer> consists of just one property.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_conv_layers, max_dense_layers, max_filters,\n",
    "                 max_dense_nodes, input_shape, n_classes,\n",
    "                 batch_normalization=True, dropout=True, max_pooling=True,\n",
    "                 optimizers=None, activations=None):\n",
    "        \"\"\"\n",
    "        Creates a GenomeHandler according\n",
    "        Args:\n",
    "            max_conv_layers: The maximum number of convolutional layers\n",
    "            max_dense_layers: The maximum number of dense (fully connected)\n",
    "                    layers, including output layer\n",
    "            max_filters: The maximum number of conv filters (feature maps) in a\n",
    "                    convolutional layer\n",
    "            max_dense_nodes: The maximum number of nodes in a dense layer\n",
    "            input_shape: The shape of the input\n",
    "            n_classes: The number of classes\n",
    "            batch_normalization (bool): whether the GP should include batch norm\n",
    "            dropout (bool): whether the GP should include dropout\n",
    "            max_pooling (bool): whether the GP should include max pooling layers\n",
    "            optimizers (list): list of optimizers to be tried by the GP. By\n",
    "                    default, the network uses Keras's built-in adam, rmsprop,\n",
    "                    adagrad, and adadelta\n",
    "            activations (list): list of activation functions to be tried by the\n",
    "                    GP. By default, relu and sigmoid.\n",
    "        \"\"\"\n",
    "        if max_dense_layers < 1:\n",
    "            raise ValueError(\n",
    "                \"At least one dense layer is required for softmax layer\"\n",
    "            )\n",
    "        if max_filters > 0:\n",
    "            filter_range_max = int(math.log(max_filters, 2)) + 1\n",
    "        else:\n",
    "            filter_range_max = 0\n",
    "        self.optimizer = optimizers or [\n",
    "            'adam',\n",
    "            'rmsprop',\n",
    "            'adagrad',\n",
    "            'adadelta'\n",
    "        ]\n",
    "        self.activation = activations or [\n",
    "            'relu',\n",
    "            'sigmoid',\n",
    "        ]\n",
    "        self.convolutional_layer_shape = [\n",
    "            \"active\",\n",
    "            \"num filters\",\n",
    "            \"batch normalization\",\n",
    "            \"activation\",\n",
    "            \"dropout\",\n",
    "            \"max pooling\",\n",
    "        ]\n",
    "        self.dense_layer_shape = [\n",
    "            \"active\",\n",
    "            \"num nodes\",\n",
    "            \"batch normalization\",\n",
    "            \"activation\",\n",
    "            \"dropout\",\n",
    "        ]\n",
    "        self.layer_params = {\n",
    "            \"active\": [0, 1],\n",
    "            \"num filters\": [2**i for i in range(3, filter_range_max)],\n",
    "            \"num nodes\": [2**i for i in range(4, int(math.log(max_dense_nodes, 2)) + 1)],\n",
    "            \"batch normalization\": [0, (1 if batch_normalization else 0)],\n",
    "            \"activation\": list(range(len(self.activation))),\n",
    "            \"dropout\": [(i if dropout else 0) for i in range(11)],\n",
    "            \"max pooling\": list(range(3)) if max_pooling else 0,\n",
    "        }\n",
    "\n",
    "        self.convolution_layers = max_conv_layers\n",
    "        self.convolution_layer_size = len(self.convolutional_layer_shape)\n",
    "        self.dense_layers = max_dense_layers - 1  # this doesn't include the softmax layer, so -1\n",
    "        self.dense_layer_size = len(self.dense_layer_shape)\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def convParam(self, i):\n",
    "        key = self.convolutional_layer_shape[i]\n",
    "        return self.layer_params[key]\n",
    "\n",
    "    def denseParam(self, i):\n",
    "        key = self.dense_layer_shape[i]\n",
    "        return self.layer_params[key]\n",
    "\n",
    "    def mutate(self, genome, num_mutations):\n",
    "        #copy = genome.copy()\n",
    "        num_mutations = np.random.choice(num_mutations)\n",
    "        for i in range(num_mutations):\n",
    "            index = np.random.choice(list(range(1, len(genome))))\n",
    "            if index < self.convolution_layer_size * self.convolution_layers:\n",
    "                if genome[index - index % self.convolution_layer_size]:\n",
    "                    range_index = index % self.convolution_layer_size\n",
    "                    choice_range = self.convParam(range_index)\n",
    "                    genome[index] = np.random.choice(choice_range)\n",
    "                elif rand.uniform(0, 1) <= 0.01:  # randomly flip deactivated layers\n",
    "                    genome[index - index % self.convolution_layer_size] = 1\n",
    "            elif index != len(genome) - 1:\n",
    "                offset = self.convolution_layer_size * self.convolution_layers\n",
    "                new_index = (index - offset)\n",
    "                present_index = new_index - new_index % self.dense_layer_size\n",
    "                if genome[present_index + offset]:\n",
    "                    range_index = new_index % self.dense_layer_size\n",
    "                    choice_range = self.denseParam(range_index)\n",
    "                    genome[index] = np.random.choice(choice_range)\n",
    "                elif rand.uniform(0, 1) <= 0.01:\n",
    "                    genome[present_index + offset] = 1\n",
    "            else:\n",
    "                genome[index] = np.random.choice(list(range(len(self.optimizer))))\n",
    "            \n",
    "        while not self.is_compatible_genome(genome):\n",
    "            genome = self.generate()\n",
    "                \n",
    "                \n",
    "        return genome\n",
    "\n",
    "    def decode(self, genome):\n",
    "        try:\n",
    "          if not self.is_compatible_genome(genome):\n",
    "              genome = self.generate()\n",
    "        except:\n",
    "          genome = self.generate()\n",
    "        model = Sequential()\n",
    "        dim = 0\n",
    "        offset = 0\n",
    "        if self.convolution_layers > 0:\n",
    "            dim = min(self.input_shape[:-1])  # keep track of smallest dimension\n",
    "        input_layer = True\n",
    "        for i in range(self.convolution_layers):\n",
    "            if genome[offset]:\n",
    "                convolution = None\n",
    "                if input_layer:\n",
    "                    convolution = Convolution2D(\n",
    "                        genome[offset + 1], (3, 3),\n",
    "                        padding='same',\n",
    "                        input_shape=self.input_shape\n",
    "                    )\n",
    "                    input_layer = False\n",
    "                else:\n",
    "                    convolution = Convolution2D(\n",
    "                        genome[offset + 1], (3, 3),\n",
    "                        padding='same'\n",
    "                    )\n",
    "                model.add(convolution)\n",
    "                if genome[offset + 2]:\n",
    "                    model.add(BatchNormalization())\n",
    "                model.add(Activation(self.activation[genome[offset + 3]]))\n",
    "                model.add(Dropout(float(genome[offset + 4] / 20.0)))\n",
    "                max_pooling_type = genome[offset + 5]\n",
    "                # must be large enough for a convolution\n",
    "                if max_pooling_type == 1 and dim >= 5:\n",
    "                    model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "                    dim = int(math.ceil(dim / 2))\n",
    "            offset += self.convolution_layer_size\n",
    "\n",
    "        if not input_layer:\n",
    "            model.add(Flatten())\n",
    "\n",
    "        for i in range(self.dense_layers):\n",
    "            if genome[offset]:\n",
    "                dense = None\n",
    "                if input_layer:\n",
    "                    dense = Dense(genome[offset + 1], input_shape=self.input_shape)\n",
    "                    input_layer = False\n",
    "                else:\n",
    "                    dense = Dense(genome[offset + 1])\n",
    "                model.add(dense)\n",
    "                if genome[offset + 2]:\n",
    "                    model.add(BatchNormalization())\n",
    "                model.add(Activation(self.activation[genome[offset + 3]]))\n",
    "                model.add(Dropout(float(genome[offset + 4] / 20.0)))\n",
    "            offset += self.dense_layer_size\n",
    "\n",
    "        model.add(Dense(self.n_classes, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=self.optimizer[genome[offset]],\n",
    "                      metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "    def genome_representation(self):\n",
    "        encoding = []\n",
    "        for i in range(self.convolution_layers):\n",
    "            for key in self.convolutional_layer_shape:\n",
    "                encoding.append(\"Conv\" + str(i) + \" \" + key)\n",
    "        for i in range(self.dense_layers):\n",
    "            for key in self.dense_layer_shape:\n",
    "                encoding.append(\"Dense\" + str(i) + \" \" + key)\n",
    "        encoding.append(\"Optimizer\")\n",
    "        return encoding\n",
    "\n",
    "    def generate(self):\n",
    "        genome = []\n",
    "        for i in range(self.convolution_layers):\n",
    "            for key in self.convolutional_layer_shape:\n",
    "                param = self.layer_params[key]\n",
    "                genome.append(np.random.choice(param))\n",
    "        for i in range(self.dense_layers):\n",
    "            for key in self.dense_layer_shape:\n",
    "                param = self.layer_params[key]\n",
    "                genome.append(np.random.choice(param))\n",
    "        genome.append(np.random.choice(list(range(len(self.optimizer)))))\n",
    "        genome[0] = 1\n",
    "        return genome\n",
    "\n",
    "    def is_compatible_genome(self, genome):\n",
    "        expected_len = self.convolution_layers * self.convolution_layer_size \\\n",
    "            + self.dense_layers * self.dense_layer_size + 1\n",
    "        if len(genome) != expected_len:\n",
    "            return False\n",
    "        ind = 0\n",
    "        for i in range(self.convolution_layers):\n",
    "            for j in range(self.convolution_layer_size):\n",
    "                if genome[ind + j] not in self.convParam(j):\n",
    "                    return False\n",
    "            ind += self.convolution_layer_size\n",
    "        for i in range(self.dense_layers):\n",
    "            for j in range(self.dense_layer_size):\n",
    "                if genome[ind + j] not in self.denseParam(j):\n",
    "                    return False\n",
    "            ind += self.dense_layer_size\n",
    "        if genome[ind] not in range(len(self.optimizer)):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def best_genome(self, csv_path, metric=\"accuracy\", include_metrics=True):\n",
    "        best = max if metric is \"accuracy\" else min\n",
    "        col = -1 if metric is \"accuracy\" else -2\n",
    "        data = np.genfromtxt(csv_path, delimiter=\",\")\n",
    "        row = list(data[:, col]).index(best(data[:, col]))\n",
    "        genome = list(map(int, data[row, :-2]))\n",
    "        if include_metrics:\n",
    "            genome += list(data[row, -2:])\n",
    "        return genome\n",
    "\n",
    "    def decode_best(self, csv_path, metric=\"accuracy\"):\n",
    "        return self.decode(self.best_genome(csv_path, metric, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "984577c5-32d9-4b8f-b144-cfd5dfc1c80e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# DEvol On MNIST Results\n",
    "### Genome Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e25f5feb-08b5-4721-96db-6dfc157a9eaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6fb74443-e2fd-4e6d-ad6b-2b502e8011f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "dataset = ((x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a5d891fd-e19e-4e1f-b013-83e6cd5b7e23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[48]: (28, 28, 1)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[48]: (28, 28, 1)</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c67b767b-782f-4e6c-abe9-d427b7f01376",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "genome_handler = GenomeHandler(max_conv_layers=6, \n",
    "                               max_dense_layers=2, # includes final dense layer\n",
    "                               max_filters=256,\n",
    "                               max_dense_nodes=1024,\n",
    "                               input_shape=x_train.shape[1:],\n",
    "                               n_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3657abd5-b2c8-4fce-9684-5452bd3ba671",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Genome encoding and metric data stored at /dbfs/FileStore/runs/_hill_climberSat_Nov_28_01-42-44_2020record.csv \n",
       "\n",
       "\n",
       "model 1/2 - generation 1/2:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "\n",
       "model 2/2 - generation 1/2:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "Generation 1:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\n",
       "\n",
       "model 1/2 - generation 2/2:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "\n",
       "model 2/2 - generation 2/2:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "Generation 2:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\n",
       "Out[50]: 1</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Genome encoding and metric data stored at /dbfs/FileStore/runs/_hill_climberSat_Nov_28_01-42-44_2020record.csv \n\n\nmodel 1/2 - generation 1/2:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\n\nmodel 2/2 - generation 1/2:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\nGeneration 1:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\n\nmodel 1/2 - generation 2/2:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\n\nmodel 2/2 - generation 2/2:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\nGeneration 2:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\nOut[50]: 1</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "devol = DEvol(genome_handler)\n",
    "devol.run(dataset=dataset,\n",
    "                  num_generations=2,\n",
    "                  pop_size=2,\n",
    "                  epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5baa31bb-578d-4093-8969-a99ec7c50750",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Genome encoding and metric data stored at /dbfs/FileStore/runs/_hill_climberSat_Nov_28_01-43-48_2020record.csv \n",
       "\n",
       "\n",
       "model 1/4 - generation 1/10:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "\n",
       "model 2/4 - generation 1/10:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "\n",
       "model 3/4 - generation 1/10:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "\n",
       "model 4/4 - generation 1/10:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "Generation 1:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\n",
       "\n",
       "model 1/3 - generation 2/10:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "\n",
       "model 2/3 - generation 2/10:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "\n",
       "model 3/3 - generation 2/10:\n",
       "\n",
       "Train on 54000 samples, validate on 6000 samples\n",
       "Epoch 1/1\n",
       "Generation 2:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Genome encoding and metric data stored at /dbfs/FileStore/runs/_hill_climberSat_Nov_28_01-43-48_2020record.csv \n\n\nmodel 1/4 - generation 1/10:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\n\nmodel 2/4 - generation 1/10:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\n\nmodel 3/4 - generation 1/10:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\n\nmodel 4/4 - generation 1/10:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\nGeneration 1:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\n\nmodel 1/3 - generation 2/10:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\n\nmodel 2/3 - generation 2/10:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\n\nmodel 3/3 - generation 2/10:\n\nTrain on 54000 samples, validate on 6000 samples\nEpoch 1/1\nGeneration 2:\t\tbest accuracy: 0.0000\t\taverage:0.0000\t\tstd: 0.0000\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4434254490332457&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>                   num_generations<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                   pop_size<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">4</span><span class=\"ansi-blue-fg\">,</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">                   epochs=1)\n",
       "</span>\n",
       "<span class=\"ansi-green-fg\">&lt;command-4275497423460486&gt;</span> in <span class=\"ansi-cyan-fg\">run</span><span class=\"ansi-blue-fg\">(self, dataset, num_generations, pop_size, epochs, fitness, metric)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    136</span>         <span class=\"ansi-red-fg\"># evolve</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    137</span>         <span class=\"ansi-green-fg\">for</span> gen <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> num_generations<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 138</span><span class=\"ansi-red-fg\">             </span>members <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_reproduce<span class=\"ansi-blue-fg\">(</span>pop<span class=\"ansi-blue-fg\">,</span> gen<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    139</span>             <span class=\"ansi-red-fg\">#!!! map to pandas df, apply udf parallel training, save scores</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    140</span>             pop = self._evaluate_population(members,\n",
       "\n",
       "<span class=\"ansi-green-fg\">&lt;command-4275497423460486&gt;</span> in <span class=\"ansi-cyan-fg\">_reproduce</span><span class=\"ansi-blue-fg\">(self, pop, gen)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    159</span>         <span class=\"ansi-red-fg\"># randomly mutate</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>         <span class=\"ansi-green-fg\">for</span> imem<span class=\"ansi-blue-fg\">,</span> mem <span class=\"ansi-green-fg\">in</span> enumerate<span class=\"ansi-blue-fg\">(</span>members<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 161</span><span class=\"ansi-red-fg\">             </span>members<span class=\"ansi-blue-fg\">[</span>imem<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_mutate<span class=\"ansi-blue-fg\">(</span>mem<span class=\"ansi-blue-fg\">,</span> gen<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    162</span>         <span class=\"ansi-green-fg\">return</span> members\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    163</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">&lt;command-4275497423460486&gt;</span> in <span class=\"ansi-cyan-fg\">_mutate</span><span class=\"ansi-blue-fg\">(self, genome, generation)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    276</span>         <span class=\"ansi-red-fg\"># increase mutations as program continues</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    277</span>         <span class=\"ansi-red-fg\">#num_mutations = max(3, generation // 4)</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 278</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>genome_handler<span class=\"ansi-blue-fg\">.</span>mutate<span class=\"ansi-blue-fg\">(</span>genome<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>pop_size<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    279</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    280</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">&lt;command-4275497423460487&gt;</span> in <span class=\"ansi-cyan-fg\">mutate</span><span class=\"ansi-blue-fg\">(self, genome, num_mutations)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>         num_mutations <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>random<span class=\"ansi-blue-fg\">.</span>choice<span class=\"ansi-blue-fg\">(</span>num_mutations<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-green-fg\">for</span> i <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span>num_mutations<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">             </span>index <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>random<span class=\"ansi-blue-fg\">.</span>choice<span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">(</span>range<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> len<span class=\"ansi-blue-fg\">(</span>genome<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>             <span class=\"ansi-green-fg\">if</span> index <span class=\"ansi-blue-fg\">&lt;</span> self<span class=\"ansi-blue-fg\">.</span>convolution_layer_size <span class=\"ansi-blue-fg\">*</span> self<span class=\"ansi-blue-fg\">.</span>convolution_layers<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    112</span>                 <span class=\"ansi-green-fg\">if</span> genome<span class=\"ansi-blue-fg\">[</span>index <span class=\"ansi-blue-fg\">-</span> index <span class=\"ansi-blue-fg\">%</span> self<span class=\"ansi-blue-fg\">.</span>convolution_layer_size<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">TypeError</span>: object of type &#39;numpy.int64&#39; has no len()</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4434254490332457&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>                   num_generations<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">10</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                   pop_size<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">4</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\">                   epochs=1)\n</span>\n<span class=\"ansi-green-fg\">&lt;command-4275497423460486&gt;</span> in <span class=\"ansi-cyan-fg\">run</span><span class=\"ansi-blue-fg\">(self, dataset, num_generations, pop_size, epochs, fitness, metric)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    136</span>         <span class=\"ansi-red-fg\"># evolve</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    137</span>         <span class=\"ansi-green-fg\">for</span> gen <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> num_generations<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 138</span><span class=\"ansi-red-fg\">             </span>members <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_reproduce<span class=\"ansi-blue-fg\">(</span>pop<span class=\"ansi-blue-fg\">,</span> gen<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    139</span>             <span class=\"ansi-red-fg\">#!!! map to pandas df, apply udf parallel training, save scores</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    140</span>             pop = self._evaluate_population(members,\n\n<span class=\"ansi-green-fg\">&lt;command-4275497423460486&gt;</span> in <span class=\"ansi-cyan-fg\">_reproduce</span><span class=\"ansi-blue-fg\">(self, pop, gen)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    159</span>         <span class=\"ansi-red-fg\"># randomly mutate</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    160</span>         <span class=\"ansi-green-fg\">for</span> imem<span class=\"ansi-blue-fg\">,</span> mem <span class=\"ansi-green-fg\">in</span> enumerate<span class=\"ansi-blue-fg\">(</span>members<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 161</span><span class=\"ansi-red-fg\">             </span>members<span class=\"ansi-blue-fg\">[</span>imem<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_mutate<span class=\"ansi-blue-fg\">(</span>mem<span class=\"ansi-blue-fg\">,</span> gen<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    162</span>         <span class=\"ansi-green-fg\">return</span> members\n<span class=\"ansi-green-intense-fg ansi-bold\">    163</span> \n\n<span class=\"ansi-green-fg\">&lt;command-4275497423460486&gt;</span> in <span class=\"ansi-cyan-fg\">_mutate</span><span class=\"ansi-blue-fg\">(self, genome, generation)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    276</span>         <span class=\"ansi-red-fg\"># increase mutations as program continues</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    277</span>         <span class=\"ansi-red-fg\">#num_mutations = max(3, generation // 4)</span>\n<span class=\"ansi-green-fg\">--&gt; 278</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>genome_handler<span class=\"ansi-blue-fg\">.</span>mutate<span class=\"ansi-blue-fg\">(</span>genome<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>pop_size<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    279</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    280</span> \n\n<span class=\"ansi-green-fg\">&lt;command-4275497423460487&gt;</span> in <span class=\"ansi-cyan-fg\">mutate</span><span class=\"ansi-blue-fg\">(self, genome, num_mutations)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>         num_mutations <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>random<span class=\"ansi-blue-fg\">.</span>choice<span class=\"ansi-blue-fg\">(</span>num_mutations<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-green-fg\">for</span> i <span class=\"ansi-green-fg\">in</span> range<span class=\"ansi-blue-fg\">(</span>num_mutations<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">             </span>index <span class=\"ansi-blue-fg\">=</span> np<span class=\"ansi-blue-fg\">.</span>random<span class=\"ansi-blue-fg\">.</span>choice<span class=\"ansi-blue-fg\">(</span>list<span class=\"ansi-blue-fg\">(</span>range<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> len<span class=\"ansi-blue-fg\">(</span>genome<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>             <span class=\"ansi-green-fg\">if</span> index <span class=\"ansi-blue-fg\">&lt;</span> self<span class=\"ansi-blue-fg\">.</span>convolution_layer_size <span class=\"ansi-blue-fg\">*</span> self<span class=\"ansi-blue-fg\">.</span>convolution_layers<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    112</span>                 <span class=\"ansi-green-fg\">if</span> genome<span class=\"ansi-blue-fg\">[</span>index <span class=\"ansi-blue-fg\">-</span> index <span class=\"ansi-blue-fg\">%</span> self<span class=\"ansi-blue-fg\">.</span>convolution_layer_size<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: object of type &#39;numpy.int64&#39; has no len()</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">TypeError</span>: object of type &#39;numpy.int64&#39; has no len()",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "devol = DEvol(genome_handler)\n",
    "devol.run(dataset=dataset,\n",
    "                  num_generations=10,\n",
    "                  pop_size=4,\n",
    "                  epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "23574dfd-9743-48e0-a773-e95baf8caa62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "devol = DEvol(genome_handler)\n",
    "devol.run(dataset=dataset,\n",
    "                  num_generations=10,\n",
    "                  pop_size=4,\n",
    "                  epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dd593d68-1b12-434c-864d-859981998cbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "hill climber",
   "notebookOrigID": 4275497423460481,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
